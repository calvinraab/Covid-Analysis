---
title: "Project1RMD"
author: "Group"
date: "4/15/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Here is where we can put our work. I imagine this is what we will turn in. 

Here I am uploading the original datasets: 
```{r}
library(readr)
library(dplyr)
library(leaps)
library(ggplot2)
library(reshape2)
library(scales)
library(corrplot)
library(car)

Fat_Supply_Quantity_Data <- read_csv("Fat_Supply_Quantity_Data.csv")
Food_Supply_Quantity_kg_Data <- read_csv("Food_Supply_Quantity_kg_Data.csv")
Food_Supply_kcal_Data <- read_csv("Food_Supply_kcal_Data.csv")
Protein_Supply_Quantity_Data <- read_csv("Protein_Supply_Quantity_Data.csv")
Supply_Food_Data_Descriptions <- read_csv("Supply_Food_Data_Descriptions.csv")
glimpse(Fat_Supply_Quantity_Data)
```

Data cleaning process. Here we can clean up that data and get it cleaned to the point where we will be able to work with it. 
```{r}
#select columns that are not filled with zeros
Fat_Supply_data <- Fat_Supply_Quantity_Data %>% select(Country, `Animal Products`, `Animal fats`, `Cereals - Excluding Beer`, Eggs, `Fish, Seafood`, `Fruits - Excluding Wine`, Meat, `Milk - Excluding Butter`, Offals, Oilcrops, Pulses, Spices, `Starchy Roots`, Stimulants, Treenuts, `Vegetal Products`, `Vegetable Oils`, Vegetables, Obesity, Undernourished, Population, Confirmed, Deaths)

Fat_Supply_data <- Fat_Supply_data[Fat_Supply_data$Deaths > 0,]
Fat_Supply_data <- Fat_Supply_data[!is.na(Fat_Supply_data$Deaths),]


Fat_Supply_data$Undernourished[Fat_Supply_data$Undernourished == "<2.5"] <- 2.5
Fat_Supply_data$Undernourished <- as.numeric(Fat_Supply_data$Undernourished)

# replace NAs in Obesity and Undernourished with the median values
Fat_Supply_data$Obesity[is.na(Fat_Supply_data$Obesity)] <- median(Fat_Supply_data$Obesity, na.rm=TRUE)
Fat_Supply_data$Undernourished[is.na(Fat_Supply_data$Undernourished)] <- median(Fat_Supply_data$Undernourished, na.rm=TRUE)

data <- Fat_Supply_data

# Here is a dataset that includes the parameters found in backAIC, along with: Country, Population, Confirmed, and Deaths (Using For Analysis) 
backAICdata.plus <- data_frame(data$`Country`, data$`Animal fats`, data$`Cereals - Excluding Beer`, data$`Fruits - Excluding Wine`, data$`Oilcrops`, data$`Pulses`, data$`Spices`, data$`Starchy Roots`, data$Stimulants, data$Treenuts, data$`Vegetal Products`, data$`Vegetable Oils`, data$Vegetables, data$Obesity, data$Undernourished, data$Population, data$Confirmed, data$Deaths)

names(backAICdata.plus) <- c("Country", "Animal_Fats", "Cereals", "Fruits", "Oilcrops", "Pulses", "Spices", "Starchy_Roots", "Stimulants", "Treenuts", "Vegetal Products", "Vegetable_Oils", "Vegetables", "Obesity", "Undernourished", "Population", "Confirmed", "Deaths")


```

### Part 1 
Provide a descriptive analysis of your variables. This should include histograms and fitted distributions, correlation plot, boxplots, scatterplots, and statistical summaries (e.g., the five-number summary). All figures must include comments.

Columns in dataset:  
* Fat Supply Measures - Average percentage (out of 100) of fat in diet that comes from each category of food
    - Categories included: Animal_Fats, Cereals, Fruits, Oilcrops, Pulses, Spices, Starchy_Roots, Stimulants, Treenuts, Vegetal Products, Vegetable_oils, and Vegetables
    
* Population Health Measures - Percentage of the population that falls into each category
    - Obesity and Undernourished
    
* Population and COVID Measures
    - Population - Population of country
    - Confirmed - Percentage of population with a confirmed positive test for COVID-19
    - Deaths - Percentage of population that died from COVID-19
    

```{r}
# create a boxplot of food categories


# melt the data into long form
fat_data <- melt(backAICdata.plus[,1:13], id = "Country")

# create boxplots
ggplot(fat_data, aes(x = variable, y = value)) +
  geom_boxplot() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  scale_y_continuous(labels = label_percent(scale = 1)) +
  xlab("Food Category") +
  ylab("Percentage of Fat") +
  ggtitle("Boxplot of Percentage of Fat in Diet from Food Categories")
```

From the above boxplots, we can see that Vegetal Products and Vegetable Oils are major sources of fat for all countries, whike the average values for other categories are low. We can also see that Oilcrops has a relatively large amount of high outliers compared to other groups.  

```{r}
# correlation plot of all variables
library(corrplot)
corrplot(cor(backAICdata.plus[,-1]), method = "circle")
```

From the above correlation plot, we can see some interesting correlations between some food groups, such as between Vetegal Procucts and Animal Fats. We also see that Obesity and Undernourished are strongly negatively correlated, which makes sense, and that there is a very high correlation between Confirmed Cases and Deaths, which is also to be expected. 


```{r}
# five number summaries for each numeric column

apply(backAICdata.plus[,-1], 2, summary)


```


```{r}
library(ggplot2)
# Percentage of confirmed cases by country - I want to only post the labels of countries that have over a 5% confirmed case level 
ggplot(data = backAICdata.plus, aes(x=Country, y=Confirmed, label= Country)) + geom_point() + geom_text(check_overlap = TRUE) + scale_x_discrete(guide = guide_axis(check.overlap = TRUE))
```


### Part 2
Estimate a multiple linear regression model that includes all the main effects only (i.e., no interactions nor higher order terms). We will use this model as a baseline. Comment on the statistical and economic significance of your estimates. Also, make sure to provide an interpretation of your estimates.
```{r}

# To reduce the number of columns in our dataset to a more workable amount, 
# we used backward selection with AIC to pick the predictors we wanted to include. 
# The dataset used for question one used only the selected columns.

model_all <- lm(data$Deaths ~ data$`Animal Products` + data$`Animal fats` + data$`Cereals - Excluding Beer` + data$Eggs + data$`Fish, Seafood` + data$`Fruits - Excluding Wine` + data$Meat + data$`Milk - Excluding Butter` + data$Offals + data$Oilcrops + data$Pulses + data$Spices + data$`Starchy Roots` + data$Stimulants + data$Treenuts + data$`Vegetal Products` + data$`Vegetable Oils` + data$Vegetables + data$Obesity + data$Undernourished + data$Population)

#summary(model_all)

n <- length(data$Deaths)

backAIC <- step(model_all ,direction="backward", data=data)
summary(backAIC)
# backBIC <- step(model_all ,direction="backward", data=data, k = log(n))

# Baseline Model 
backAIC
```

As can be seen in the model output above, all food categories are statistically significant at the $\alpha = .05$ level. Obesity is also a statistically significant predictor, though Undernourished is surprisingly not statistically significant. The magnitude of the estimates for the food categories is roughly the same, with a 1% increase in fat from each food category leading to a .17 - .19 percent change in expected death rate from COVID-19. What is interesting is that Vegetal Products is the only statistically significant predictor with a negative coefficient, while all other food categories are positive. An increase of 1% in population obesity leads to an increase in .001% of expected COVID-19 death rate.  

### Part 3
Identify if there are any outliers, high leverage, and or influential observations worth removing. If so, remove them but justify your reason for doing so and re-estimate your model.


```{r}

# https://cran.r-project.org/web/packages/olsrr/vignettes/influence_measures.html
library(olsrr)
library(car)


plot(backAIC)

influencePlot(backAIC, id=list(n=3)) 
ols_plot_resid_lev(backAIC)


# These are the observations both graphs agree on

## high leverage (x) = 120 (Rwanda), 90 (Maldives), 47 (Ethiopia)
## influential (y and x) = 19 (Bosnia/Herzegovina)
## outlier (y) = 103 (New Zealand), 113 (Peru)

# Remove  unusual observations with slice 

no_highleverage <- backAICdata.plus %>% slice(-c(120,90,47))
no_influential <- backAICdata.plus %>% slice(-19)
no_outlier <- backAICdata.plus %>% slice(-c(103,113))
no_unusual_observations <- backAICdata.plus %>% slice(-c(120,90,47,19,103,113))

no_unusual_observations
backAICdata.plus

# Re-estimate the models to see without unusual observations

modeltest <- lm(backAIC, data = no_unusual_observations)
summary(modeltest)
summary(backAIC)

# These are the same models?
# influencePlot(new_model_1, id=list(n=3)) 
# ols_plot_resid_lev(modeltest)

# New model 
new_model_1 <- lm(Deaths~Animal_Fats+Cereals+Fruits+Oilcrops+Pulses+Spices+Starchy_Roots+Stimulants+Treenuts+`Vegetal Products`+Vegetable_Oils+Vegetables+Obesity, data=no_unusual_observations)
summary(new_model_1)

```

### Part 4
Use Mallows Cp for identifying which terms you will keep in the model (based on part 3) and also use the Boruta algorithm for variable selection. Based on the two results, determine which subset of predictors you will keep.
```{r}
# Here we will use Mallows CP and Boruta which will estimate a new model.
# Mallows CP - Here we will be testing between the two models that we created part 3
# Since Mallows CP has a lower number when testing our new_model_1, we will proceed with that model. 
ols_mallows_cp(new_model_1, model_all)
ols_mallows_cp(backAIC, model_all)

# install.packages("Boruta")
library(Boruta)

Bor.res <- Boruta(Deaths~Animal_Fats+Cereals+Fruits+Oilcrops+Pulses+Spices+Starchy_Roots+Stimulants+Treenuts+`Vegetal Products`+Vegetable_Oils+Vegetables+Obesity, data = no_unusual_observations, doTrace = 2 )
# plot(Bor.res, xlab = "", xaxt = "n", main = "Boruta Algorithim")
lz<-lapply(1:ncol(Bor.res$ImpHistory),function(i)
Bor.res$ImpHistory[is.finite(Bor.res$ImpHistory[,i]),i])
names(lz) <- colnames(Bor.res$ImpHistory)
Labels <- sort(sapply(lz,median))
plot(Bor.res, xlab = "Attributes", main = "Boruta Algorithim")
# Fix labels

# Testing to see which variables we want to remove
attStats(Bor.res)
sorted_vars <- attStats(Bor.res)[order(-attStats(Bor.res)$meanImp),]
print(sorted_vars)
# We will reject: Stimulants, Treenuts, Starchy Roots, Vegetables, Spices, Fruits


# Our New Model 
new_model_2 <- lm(Deaths~Animal_Fats+Cereals+Oilcrops+Pulses+`Vegetal Products`+Vegetable_Oils+Obesity, data=no_unusual_observations)
summary(new_model_2)
```


### Part 5
Test for multicollinearity using VIF on the model from (4) . Based on the test, remove any appropriate variables, and estimate a new regression model based on these findings.
```{r}
vif(new_model_2) # We will remove any variable with a VIF over 10 to satisfy collinearity assumption

# Remove: OilCrops, Vegetal Products, and Vegtable Oils 
new_model_3 <- lm(Deaths~Animal_Fats+Cereals+Pulses+Obesity, data=no_unusual_observations)

#New MOdel 
summary(new_model_3)
```


### Part 6
For your model in part (5) plot the respective residuals vs. y_hat  and comment on your results.

From the residuals vs fitted plot it can be seen that our residuals appear to spread out the greater our fitted value is. The red smoother runs close to zero which is a good thing. 
```{r}
par(mfrow=c(2,2))
plot(new_model_3)

```


### Part 7
For your model in part (5) perform a RESET test and comment on your results.

Here we tested our model by testing our model against a quadratic. Our result is a p-value of 0.1389 which means we should consider higher order powers. 
```{r}
library(lmtest)

resettest(new_model_3, power = 2, type = "regressor")
```


### Part 8
For your model in part (5) test for heteroskedasticity and comment on your results. If you identify heteroskedasticy, make sure to account for it before moving on to (9).

Below we will test for heteroskedacity using the ncvTest, bptest, and the gqtest. 
```{r}
# Non-constant error variance: Ho: variance = constant 
ncvTest(new_model_3) # Reject Ho

# BP test 
bptest(new_model_3) #Reject Ho

# GQ Test  (not too sure what to order by here)
# gqtest(new_model_3, point = .5, alternative = "greater", order.by = model_vif$Obesity) 
#need to figure out what to order by 
```

From the above tests it can be seen that heteroskedacity is present in our data. In order to account for that we will now run our model with robust white standard errors. Here our new standard errors can be found. 
```{r}
cov1 <- hccm(new_model_3, type = "hc1")
#Have our model account for those errors. 
new_model_3_adjusted <- coeftest(new_model_3, vcov. = cov1)
library(broom)
tidy(new_model_3_adjusted)
```

### Part 9
Estimate a model based on all your findings that also includes interaction terms (if appropriate) and if needed, any higher power terms. Comment on the performance of this model compared to your other models. Make sure to use AIC and BIC for model comparison.
```{r}

```

### Part 10
Evaluate your model performance (from 9) using cross-validation, and also by dividing your data into the traditional 2/3 training and 1/3 testing samples, to evaluate your out-of-sample performance. Comment on your results. 
```{r}
# install.packages("caret")
# install.packages("lattice")
library(caret)
model_final <- new_model_3 # replace this with the model from 9 once we have it

# split data into 2/3 train 1/3 test
train <- sample(nrow(data), nrow(data) * 2/3)
data_train <- data[train,]
data_test <- data[-train,]

# do 5-fold cross validation on the training partition
# using model_vif below as placeholder
fitControl <- trainControl(method="cv", number = 5, savePredictions = T)
model_cv <- train(Deaths ~  `Cereals - Excluding Beer` + Eggs + `Fish, Seafood` + `Fruits - Excluding Wine` + Meat + `Milk - Excluding Butter` + Offals + Oilcrops + Pulses + Spices + `Starchy Roots` + Stimulants + Treenuts + Vegetables + Obesity + Undernourished + Population, data = data_train, trControl = fitControl, method = "glm")

model_cv

summary(model_cv)

# make predictions on the testing partition
pred <- predict(model_cv, data_test)

# calculate RMSE
RMSE(pred, data_test$Deaths)

```


### Part 11
Provide a short (1 paragraph) summary of your overall conclusions/findings.


